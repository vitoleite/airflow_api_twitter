{"data": [{"edit_history_tweet_ids": ["1611148254758207488"], "lang": "en", "public_metrics": {"retweet_count": 36, "reply_count": 0, "like_count": 0, "quote_count": 0, "impression_count": 0}, "created_at": "2023-01-05T23:50:52.000Z", "id": "1611148254758207488", "conversation_id": "1611148254758207488", "text": "RT @gp_pulipaka: Essential #PySpark for Scalable Data #Analytics! #BigData #DataScience #AI #MachineLearning #IoT #IIoT #Python #RStats #Te…", "author_id": "1500261531409436675"}, {"edit_history_tweet_ids": ["1611133120836964352"], "lang": "en", "public_metrics": {"retweet_count": 0, "reply_count": 1, "like_count": 2, "quote_count": 0, "impression_count": 807}, "created_at": "2023-01-05T22:50:44.000Z", "id": "1611133120836964352", "conversation_id": "1611128127241031681", "in_reply_to_user_id": "14092380", "text": "@joelgrus it knows squat about parallelizing in pyspark", "author_id": "614793146"}, {"edit_history_tweet_ids": ["1611120404290043907"], "lang": "en", "public_metrics": {"retweet_count": 0, "reply_count": 0, "like_count": 3, "quote_count": 0, "impression_count": 166}, "created_at": "2023-01-05T22:00:12.000Z", "id": "1611120404290043907", "conversation_id": "1611120404290043907", "text": "On my local machine PySpark is actually slower than pandas, then on a cloud based environment like Gitpod or Databricks, it's way faster.\n\nThen again it's not about the environment but the volume of the data and the complexity of your transformation algorithm.", "author_id": "1089703926373462026"}, {"edit_history_tweet_ids": ["1611119770983702534"], "lang": "en", "public_metrics": {"retweet_count": 6, "reply_count": 0, "like_count": 0, "quote_count": 0, "impression_count": 0}, "created_at": "2023-01-05T21:57:41.000Z", "id": "1611119770983702534", "conversation_id": "1611119770983702534", "text": "RT @databricks: It’s time to optimize 📈 PySpark UDFs and reduce ⬇️ the likelihood of out-of-memory errors.\n\nLearn how the PySpark memory pr…", "author_id": "2742938653"}, {"edit_history_tweet_ids": ["1611118074945540103"], "lang": "en", "public_metrics": {"retweet_count": 36, "reply_count": 0, "like_count": 0, "quote_count": 0, "impression_count": 0}, "created_at": "2023-01-05T21:50:56.000Z", "id": "1611118074945540103", "conversation_id": "1611118074945540103", "text": "RT @gp_pulipaka: Essential #PySpark for Scalable Data #Analytics! #BigData #DataScience #AI #MachineLearning #IoT #IIoT #Python #RStats #Te…", "author_id": "1465977386613182464"}, {"edit_history_tweet_ids": ["1611117966095011842"], "lang": "en", "public_metrics": {"retweet_count": 0, "reply_count": 0, "like_count": 1, "quote_count": 1, "impression_count": 79}, "created_at": "2023-01-05T21:50:30.000Z", "id": "1611117966095011842", "conversation_id": "1611117966095011842", "text": "Glad to share that I have successfully completed the Hadoop ecosystem belt exam in #Big_Data &amp; #AI Bootcamp provided by #Saudi_Digital_Academy and #coding_dojo #SDA #Hadoop #pyspark #pig_latin https://t.co/5l6l2jyS0s", "author_id": "1166907977099612162"}, {"edit_history_tweet_ids": ["1611109672139759616"], "lang": "en", "public_metrics": {"retweet_count": 1, "reply_count": 0, "like_count": 0, "quote_count": 0, "impression_count": 0}, "created_at": "2023-01-05T21:17:33.000Z", "id": "1611109672139759616", "conversation_id": "1611109672139759616", "text": "RT @rishabh31244444: I have urgent #remoterole   with #c2crequirements #contractjob    #role #dataengineerjobs With #datamodeler #aws #pysp…", "author_id": "4839215822"}, {"edit_history_tweet_ids": ["1611108305316859904"], "lang": "en", "public_metrics": {"retweet_count": 1, "reply_count": 0, "like_count": 0, "quote_count": 0, "impression_count": 2}, "created_at": "2023-01-05T21:12:07.000Z", "id": "1611108305316859904", "conversation_id": "1611108305316859904", "text": "I have urgent #remoterole   with #c2crequirements #contractjob    #role #dataengineerjobs With #datamodeler #aws #pyspark #rdbms #Triggers \n position for #directclients  #position   if you are interested, Please share your resume at …https://t.co/ox7WeevHcB", "author_id": "1577431066637656065"}, {"edit_history_tweet_ids": ["1611100510228185089"], "lang": "en", "public_metrics": {"retweet_count": 36, "reply_count": 0, "like_count": 0, "quote_count": 0, "impression_count": 0}, "created_at": "2023-01-05T20:41:09.000Z", "id": "1611100510228185089", "conversation_id": "1611100510228185089", "text": "RT @gp_pulipaka: Essential #PySpark for Scalable Data #Analytics! #BigData #DataScience #AI #MachineLearning #IoT #IIoT #Python #RStats #Te…", "author_id": "507416311"}, {"edit_history_tweet_ids": ["1611087511685562368"], "lang": "en", "public_metrics": {"retweet_count": 36, "reply_count": 0, "like_count": 0, "quote_count": 0, "impression_count": 0}, "created_at": "2023-01-05T19:49:30.000Z", "id": "1611087511685562368", "conversation_id": "1611087511685562368", "text": "RT @gp_pulipaka: Essential #PySpark for Scalable Data #Analytics! #BigData #DataScience #AI #MachineLearning #IoT #IIoT #Python #RStats #Te…", "author_id": "1699744380"}], "includes": {"users": [{"username": "RamFeg", "name": "AiiHC International", "id": "1500261531409436675", "created_at": "2022-03-06T00:08:25.000Z"}, {"username": "moonl3ss", "name": "Tito Alexikakos, xyzzy", "id": "614793146", "created_at": "2012-06-22T03:03:33.000Z"}, {"username": "kai_omni", "name": "Omni_Data_Engineer_Kai", "id": "1089703926373462026", "created_at": "2019-01-28T01:57:16.000Z"}, {"username": "HubBucket", "name": "HubBucket Inc | Discovery Invention and Innovation", "id": "2742938653", "created_at": "2014-08-18T19:53:23.000Z"}, {"username": "sonurawal931", "name": "sonal rawal", "id": "1465977386613182464", "created_at": "2021-12-01T09:34:09.000Z"}, {"username": "mo0om103", "name": "mohammed aljohani 🇺🇸🇸🇦", "id": "1166907977099612162", "created_at": "2019-08-29T02:58:49.000Z"}, {"username": "periscopeislit", "name": "Periscope Is Lit", "id": "4839215822", "created_at": "2016-01-31T09:31:50.000Z"}, {"username": "rishabh31244444", "name": "rishabh verma", "id": "1577431066637656065", "created_at": "2022-10-04T22:51:09.000Z"}, {"username": "Felix_del_alamo", "name": "Félix Alvarez", "id": "507416311", "created_at": "2012-02-28T14:04:36.000Z"}, {"username": "luckyjay666", "name": "Jie Zhang", "id": "1699744380", "created_at": "2013-08-25T17:51:58.000Z"}]}, "meta": {"newest_id": "1611148254758207488", "oldest_id": "1611087511685562368", "result_count": 10, "next_token": "b26v89c19zqg8o3fqk3zrggcfxxxxqlly01089el1pawt"}}
{"data": [{"edit_history_tweet_ids": ["1611086857499992077"], "lang": "en", "public_metrics": {"retweet_count": 0, "reply_count": 0, "like_count": 0, "quote_count": 0, "impression_count": 0}, "created_at": "2023-01-05T19:46:54.000Z", "id": "1611086857499992077", "conversation_id": "1611086857499992077", "text": "Dataplex — Data Processing using Custom Pyspark/Spark https://t.co/uFM65IEEGG", "author_id": "1197924686597939200"}, {"edit_history_tweet_ids": ["1611083023595757571"], "lang": "en", "public_metrics": {"retweet_count": 0, "reply_count": 0, "like_count": 0, "quote_count": 0, "impression_count": 22}, "created_at": "2023-01-05T19:31:39.000Z", "id": "1611083023595757571", "conversation_id": "1611083023595757571", "text": "Dataplex — Data Processing using Custom Pyspark/Spark https://t.co/YLaf3KkecH", "author_id": "9609702"}, {"edit_history_tweet_ids": ["1611082495629336577"], "lang": "en", "public_metrics": {"retweet_count": 36, "reply_count": 0, "like_count": 0, "quote_count": 0, "impression_count": 0}, "created_at": "2023-01-05T19:29:34.000Z", "id": "1611082495629336577", "conversation_id": "1611082495629336577", "text": "RT @gp_pulipaka: Essential #PySpark for Scalable Data #Analytics! #BigData #DataScience #AI #MachineLearning #IoT #IIoT #Python #RStats #Te…", "author_id": "1563916119244607488"}, {"edit_history_tweet_ids": ["1611082355422433281"], "lang": "en", "public_metrics": {"retweet_count": 36, "reply_count": 0, "like_count": 0, "quote_count": 0, "impression_count": 0}, "created_at": "2023-01-05T19:29:00.000Z", "id": "1611082355422433281", "conversation_id": "1611082355422433281", "text": "RT @gp_pulipaka: Essential #PySpark for Scalable Data #Analytics! #BigData #DataScience #AI #MachineLearning #IoT #IIoT #Python #RStats #Te…", "author_id": "1303423815955947520"}, {"edit_history_tweet_ids": ["1611077152140849152"], "lang": "en", "public_metrics": {"retweet_count": 36, "reply_count": 0, "like_count": 0, "quote_count": 0, "impression_count": 0}, "created_at": "2023-01-05T19:08:20.000Z", "id": "1611077152140849152", "conversation_id": "1611077152140849152", "text": "RT @gp_pulipaka: Essential #PySpark for Scalable Data #Analytics! #BigData #DataScience #AI #MachineLearning #IoT #IIoT #Python #RStats #Te…", "author_id": "1358689554354610176"}, {"edit_history_tweet_ids": ["1611063302817255435"], "lang": "es", "public_metrics": {"retweet_count": 1, "reply_count": 0, "like_count": 0, "quote_count": 0, "impression_count": 0}, "created_at": "2023-01-05T18:13:18.000Z", "id": "1611063302817255435", "conversation_id": "1611063302817255435", "text": "RT @IworkMadrid: Nueva Oferta ✓ Ingeniero de Datos Python/PySpark https://t.co/q5dvtmpyQL", "author_id": "3071183092"}, {"edit_history_tweet_ids": ["1611058753381535744"], "lang": "en", "public_metrics": {"retweet_count": 1, "reply_count": 0, "like_count": 0, "quote_count": 0, "impression_count": 0}, "created_at": "2023-01-05T17:55:13.000Z", "id": "1611058753381535744", "conversation_id": "1611058753381535744", "text": "RT @PysparkIsRad: Pyspark array_position function. Position of the first occurrence of the given value.\n#pyspark #spark #databricks #apache…", "author_id": "1142914136789024770"}, {"edit_history_tweet_ids": ["1611058494303571972"], "lang": "en", "public_metrics": {"retweet_count": 36, "reply_count": 0, "like_count": 0, "quote_count": 0, "impression_count": 0}, "created_at": "2023-01-05T17:54:11.000Z", "id": "1611058494303571972", "conversation_id": "1611058494303571972", "text": "RT @gp_pulipaka: Essential #PySpark for Scalable Data #Analytics! #BigData #DataScience #AI #MachineLearning #IoT #IIoT #Python #RStats #Te…", "author_id": "824070649073188865"}, {"edit_history_tweet_ids": ["1611058389945323521"], "lang": "en", "public_metrics": {"retweet_count": 36, "reply_count": 0, "like_count": 0, "quote_count": 0, "impression_count": 0}, "created_at": "2023-01-05T17:53:46.000Z", "id": "1611058389945323521", "conversation_id": "1611058389945323521", "text": "RT @gp_pulipaka: Essential #PySpark for Scalable Data #Analytics! #BigData #DataScience #AI #MachineLearning #IoT #IIoT #Python #RStats #Te…", "author_id": "1599134412402483200"}], "includes": {"users": [{"username": "fjhuerta", "name": "Javier Huerta", "id": "1197924686597939200", "created_at": "2019-11-22T17:08:03.000Z"}, {"username": "lesv", "name": "Les Vogel", "id": "9609702", "created_at": "2007-10-23T00:03:15.000Z"}, {"username": "Snehal__Borkar", "name": "Snehal Borkar", "id": "1563916119244607488", "created_at": "2022-08-28T15:47:35.000Z"}, {"username": "damianbwire88", "name": "damian bwire", "id": "1303423815955947520", "created_at": "2020-09-08T20:04:04.000Z"}, {"username": "ScottHughes007", "name": "Scott Hughes", "id": "1358689554354610176", "created_at": "2021-02-08T08:19:30.000Z"}, {"username": "JFA_unijuntos", "name": "JFA-Unijuntos", "id": "3071183092", "created_at": "2015-03-04T23:19:36.000Z"}, {"username": "PysparkIsRad", "name": "PySpark Is Rad", "id": "1142914136789024770", "created_at": "2019-06-23T21:55:39.000Z"}, {"username": "DevHighlights", "name": "Developer Highlights", "id": "824070649073188865", "created_at": "2017-01-25T01:45:28.000Z"}, {"username": "winty_updates", "name": "Winty", "id": "1599134412402483200", "created_at": "2022-12-03T20:13:13.000Z"}]}, "meta": {"newest_id": "1611086857499992077", "oldest_id": "1611058389945323521", "result_count": 9, "next_token": "b26v89c19zqg8o3fqk3zrgfg460pwnwswgf3rwv5kepod"}}
{"data": [{"author_id": "84894291", "text": "RT @gp_pulipaka: Essential #PySpark for Scalable Data #Analytics! #BigData #DataScience #AI #MachineLearning #IoT #IIoT #Python #RStats #Te…", "edit_history_tweet_ids": ["1611058354549559296"], "public_metrics": {"retweet_count": 36, "reply_count": 0, "like_count": 0, "quote_count": 0, "impression_count": 0}, "created_at": "2023-01-05T17:53:38.000Z", "conversation_id": "1611058354549559296", "id": "1611058354549559296", "lang": "en"}, {"author_id": "1284320509", "text": "Nueva Oferta ✓ Ingeniero de Datos Python/PySpark https://t.co/q5dvtmpyQL", "edit_history_tweet_ids": ["1611056445977657344"], "public_metrics": {"retweet_count": 1, "reply_count": 0, "like_count": 0, "quote_count": 0, "impression_count": 23}, "created_at": "2023-01-05T17:46:03.000Z", "conversation_id": "1611056445977657344", "id": "1611056445977657344", "lang": "es"}, {"author_id": "1577882062727413760", "text": "RT @ripulchhabra: Day 49 | PySpark | Spark Streaming | Watermarking continue \n\n#python3\n#100DaysOfCode \n#100daysofcodechallenge \n#BigData…", "edit_history_tweet_ids": ["1611052786233344001"], "public_metrics": {"retweet_count": 2, "reply_count": 0, "like_count": 0, "quote_count": 0, "impression_count": 0}, "created_at": "2023-01-05T17:31:30.000Z", "conversation_id": "1611052786233344001", "id": "1611052786233344001", "lang": "en"}, {"author_id": "1551060443040325632", "text": "RT @ripulchhabra: Day 49 | PySpark | Spark Streaming | Watermarking continue \n\n#python3\n#100DaysOfCode \n#100daysofcodechallenge \n#BigData…", "edit_history_tweet_ids": ["1611052755095023622"], "public_metrics": {"retweet_count": 2, "reply_count": 0, "like_count": 0, "quote_count": 0, "impression_count": 0}, "created_at": "2023-01-05T17:31:23.000Z", "conversation_id": "1611052755095023622", "id": "1611052755095023622", "lang": "en"}, {"author_id": "282513414", "text": "Day 49 | PySpark | Spark Streaming | Watermarking continue \n\n#python3\n#100DaysOfCode \n#100daysofcodechallenge \n#BigData \n#spark \n#Python", "edit_history_tweet_ids": ["1611052678905499648"], "public_metrics": {"retweet_count": 2, "reply_count": 0, "like_count": 2, "quote_count": 0, "impression_count": 56}, "created_at": "2023-01-05T17:31:05.000Z", "conversation_id": "1611052678905499648", "id": "1611052678905499648", "lang": "en"}, {"author_id": "14422882", "text": "With #ChatGPT helping me to design functions for pySPARK and SCALA really quick, I confirm what I have always said… being a programmer or sysadmin is boring and trivial… it is not more complex than being a designer, it is obsolete. Algorithm design is what makes you think only", "edit_history_tweet_ids": ["1611047490496724994"], "public_metrics": {"retweet_count": 0, "reply_count": 0, "like_count": 2, "quote_count": 1, "impression_count": 253}, "created_at": "2023-01-05T17:10:28.000Z", "conversation_id": "1611047490496724994", "id": "1611047490496724994", "lang": "en"}, {"author_id": "721322978311598080", "text": "RT @gp_pulipaka: Essential #PySpark for Scalable Data #Analytics! #BigData #DataScience #AI #MachineLearning #IoT #IIoT #Python #RStats #Te…", "edit_history_tweet_ids": ["1611042250024157184"], "public_metrics": {"retweet_count": 36, "reply_count": 0, "like_count": 0, "quote_count": 0, "impression_count": 0}, "created_at": "2023-01-05T16:49:38.000Z", "conversation_id": "1611042250024157184", "id": "1611042250024157184", "lang": "en"}, {"author_id": "1604873377533120513", "text": "RT @gp_pulipaka: Essential #PySpark for Scalable Data #Analytics! #BigData #DataScience #AI #MachineLearning #IoT #IIoT #Python #RStats #Te…", "edit_history_tweet_ids": ["1611041998621769750"], "public_metrics": {"retweet_count": 36, "reply_count": 0, "like_count": 0, "quote_count": 0, "impression_count": 0}, "created_at": "2023-01-05T16:48:38.000Z", "conversation_id": "1611041998621769750", "id": "1611041998621769750", "lang": "en"}, {"author_id": "777184441", "text": "RT @gp_pulipaka: Essential #PySpark for Scalable Data #Analytics! #BigData #DataScience #AI #MachineLearning #IoT #IIoT #Python #RStats #Te…", "edit_history_tweet_ids": ["1611039700856279043"], "public_metrics": {"retweet_count": 36, "reply_count": 0, "like_count": 0, "quote_count": 0, "impression_count": 0}, "created_at": "2023-01-05T16:39:31.000Z", "conversation_id": "1611039700856279043", "id": "1611039700856279043", "lang": "en"}, {"author_id": "1118179903", "text": "\"pyspark troubleshoot\" https://t.co/I9JjkmRo28 https://t.co/mDPA5I4rcC", "edit_history_tweet_ids": ["1611033307042529281"], "public_metrics": {"retweet_count": 0, "reply_count": 0, "like_count": 1, "quote_count": 0, "impression_count": 21}, "created_at": "2023-01-05T16:14:06.000Z", "conversation_id": "1611033307042529281", "id": "1611033307042529281", "lang": "de"}], "includes": {"users": [{"username": "njmube", "created_at": "2009-10-24T17:12:45.000Z", "name": "Julio", "id": "84894291"}, {"username": "IworkMadrid", "created_at": "2013-03-20T21:23:43.000Z", "name": "Trabajo Madrid", "id": "1284320509"}, {"username": "pytwt3", "created_at": "2022-10-06T04:42:58.000Z", "name": "py_twt", "id": "1577882062727413760"}, {"username": "TeddyBearIsABot", "created_at": "2022-07-24T04:23:27.000Z", "name": "🧸 Bot", "id": "1551060443040325632"}, {"username": "ripulchhabra", "created_at": "2011-04-15T10:39:29.000Z", "name": "Ripul Chhabra", "id": "282513414"}, {"username": "toorandom", "created_at": "2008-04-17T16:51:54.000Z", "name": "Eduardo ⭔", "id": "14422882"}, {"username": "bartorment", "created_at": "2016-04-16T13:02:54.000Z", "name": "Bart Torment", "id": "721322978311598080"}, {"username": "JohnMil25776716", "created_at": "2022-12-19T16:17:09.000Z", "name": "John Miller", "id": "1604873377533120513"}, {"username": "DavidAn1982", "created_at": "2012-08-24T01:55:19.000Z", "name": "David Andres Romero", "id": "777184441"}, {"username": "gio193601", "created_at": "2013-01-25T01:49:33.000Z", "name": "AnarcoCalopsitas", "id": "1118179903"}]}, "meta": {"newest_id": "1611058354549559296", "oldest_id": "1611033307042529281", "result_count": 10, "next_token": "b26v89c19zqg8o3fqk3zrgeubq5fh66ya46dc9qn8kfwd"}}
{"data": [{"author_id": "1554463481600086017", "public_metrics": {"retweet_count": 1, "reply_count": 0, "like_count": 0, "quote_count": 0, "impression_count": 0}, "created_at": "2023-01-05T16:13:04.000Z", "conversation_id": "1611033046861348868", "text": "RT @ezekvk: So I started a project recently using Pyspark with Tweepy to collect some kind of data and transform it.\n\n😭used 3 days to try a…", "lang": "en", "id": "1611033046861348868", "edit_history_tweet_ids": ["1611033046861348868"]}, {"author_id": "1172169276607913988", "public_metrics": {"retweet_count": 0, "reply_count": 0, "like_count": 0, "quote_count": 0, "impression_count": 54}, "created_at": "2023-01-05T16:09:38.000Z", "conversation_id": "1611032184097509376", "text": "For my next trick though I need to find out how to create a batch processing job with Spark and Kafka (never used it)\n\nNever done batch processing too. In completely new territory 😑. But I mean I worked around a Pyspark project soo hopefully I should be able to learn this 💪 https://t.co/3jJ9n4nQtU https://t.co/stULtXaXkZ", "lang": "en", "id": "1611032184097509376", "edit_history_tweet_ids": ["1611032184097509376"]}, {"author_id": "1172169276607913988", "public_metrics": {"retweet_count": 1, "reply_count": 0, "like_count": 1, "quote_count": 1, "impression_count": 182}, "created_at": "2023-01-05T16:06:49.000Z", "conversation_id": "1611031473779261443", "text": "So I started a project recently using Pyspark with Tweepy to collect some kind of data and transform it.\n\n😭used 3 days to try and get around using Pyspark. It's beautiful I love the flexibility it gives, running SQL queries or transforming with Python func..\n\nOfc idk it all yet", "lang": "en", "id": "1611031473779261443", "edit_history_tweet_ids": ["1611031473779261443"]}, {"author_id": "536292881", "public_metrics": {"retweet_count": 0, "reply_count": 0, "like_count": 0, "quote_count": 0, "impression_count": 11}, "created_at": "2023-01-05T16:04:37.000Z", "conversation_id": "1611030921062268929", "text": "Dataplex — Data Processing using Custom Pyspark/Spark https://t.co/tmp24erXur", "lang": "en", "id": "1611030921062268929", "edit_history_tweet_ids": ["1611030921062268929"]}, {"author_id": "14453213", "public_metrics": {"retweet_count": 0, "reply_count": 0, "like_count": 0, "quote_count": 0, "impression_count": 2}, "created_at": "2023-01-05T16:01:37.000Z", "conversation_id": "1611030163831005184", "text": "Dataplex — Data Processing using Custom Pyspark/Spark https://t.co/UQMElBFfHB", "lang": "en", "id": "1611030163831005184", "edit_history_tweet_ids": ["1611030163831005184"]}, {"author_id": "411259623", "public_metrics": {"retweet_count": 36, "reply_count": 0, "like_count": 0, "quote_count": 0, "impression_count": 0}, "created_at": "2023-01-05T15:20:21.000Z", "conversation_id": "1611019778461958145", "text": "RT @gp_pulipaka: Essential #PySpark for Scalable Data #Analytics! #BigData #DataScience #AI #MachineLearning #IoT #IIoT #Python #RStats #Te…", "lang": "en", "id": "1611019778461958145", "edit_history_tweet_ids": ["1611019778461958145"]}, {"author_id": "70773080", "public_metrics": {"retweet_count": 0, "reply_count": 1, "like_count": 0, "quote_count": 0, "impression_count": 139}, "created_at": "2023-01-05T15:07:01.000Z", "conversation_id": "1611016426298478594", "text": "Chat gpt converte query sql para pyspark, isso é lindo demais!", "lang": "pt", "id": "1611016426298478594", "edit_history_tweet_ids": ["1611016426298478594"]}, {"author_id": "1371528002270552073", "public_metrics": {"retweet_count": 36, "reply_count": 0, "like_count": 0, "quote_count": 0, "impression_count": 0}, "created_at": "2023-01-05T13:27:29.000Z", "conversation_id": "1610991376849637378", "text": "RT @gp_pulipaka: Essential #PySpark for Scalable Data #Analytics! #BigData #DataScience #AI #MachineLearning #IoT #IIoT #Python #RStats #Te…", "lang": "en", "id": "1610991376849637378", "edit_history_tweet_ids": ["1610991376849637378"]}, {"author_id": "59942191", "public_metrics": {"retweet_count": 36, "reply_count": 0, "like_count": 0, "quote_count": 0, "impression_count": 0}, "created_at": "2023-01-05T13:05:58.000Z", "conversation_id": "1610985959826362369", "text": "RT @gp_pulipaka: Essential #PySpark for Scalable Data #Analytics! #BigData #DataScience #AI #MachineLearning #IoT #IIoT #Python #RStats #Te…", "lang": "en", "id": "1610985959826362369", "edit_history_tweet_ids": ["1610985959826362369"]}, {"author_id": "3161017866", "public_metrics": {"retweet_count": 0, "reply_count": 0, "like_count": 8, "quote_count": 0, "impression_count": 164}, "created_at": "2023-01-05T12:14:17.000Z", "conversation_id": "1610972954137092099", "text": "Just 2 days left to go.\n\nOur next batch of Master Data Engineering with Spark and Databricks starts on 8th January 2023.\n\nThis course covers the following primary modules.\n1. PySpark - Beginner to advanced\n2. Databricks Cloud - Beginner to advanced\n\nThe c…https://t.co/J1vj3C6PWF", "lang": "en", "id": "1610972954137092099", "edit_history_tweet_ids": ["1610972954137092099"]}], "includes": {"users": [{"name": "Python Smart Bot", "created_at": "2022-08-02T13:46:35.000Z", "id": "1554463481600086017", "username": "py_smart_bot"}, {"name": "Eze Kingsley", "created_at": "2019-09-12T15:25:27.000Z", "id": "1172169276607913988", "username": "ezekvk"}, {"name": "Carmella Weatherill", "created_at": "2012-03-25T13:13:07.000Z", "id": "536292881", "username": "CarmellaAW"}, {"name": "plajo", "created_at": "2008-04-20T17:17:36.000Z", "id": "14453213", "username": "plajo"}, {"name": "Rahul Sathya", "created_at": "2011-11-13T05:53:14.000Z", "id": "411259623", "username": "rahulchaluvadhi"}, {"name": "arthurjordao.dev", "created_at": "2009-09-01T20:11:50.000Z", "id": "70773080", "username": "_arthurjordao"}, {"name": "Anuj&Anufan", "created_at": "2021-03-15T18:25:43.000Z", "id": "1371528002270552073", "username": "AnujKapadiafan"}, {"name": "Juan Carlos Lopera", "created_at": "2009-07-25T01:22:34.000Z", "id": "59942191", "username": "JuanKLopera"}, {"name": "Prashant Pandey", "created_at": "2015-04-17T13:04:24.000Z", "id": "3161017866", "username": "prashant_pdy"}]}, "meta": {"newest_id": "1611033046861348868", "oldest_id": "1610972954137092099", "result_count": 10, "next_token": "b26v89c19zqg8o3fqk3zcu0muvyll3f7fr7ldoky4t1ml"}}
{"data": [{"conversation_id": "1610966488709754881", "created_at": "2023-01-05T11:48:35.000Z", "public_metrics": {"retweet_count": 0, "reply_count": 0, "like_count": 0, "quote_count": 0, "impression_count": 87}, "author_id": "1533111896832102400", "text": "내일도 Emr에서 pyspark로 데이터 전처리 기능을  확인해야  다음주에 시나리오를 만들어서 교재를 만든다", "edit_history_tweet_ids": ["1610966488709754881"], "lang": "ko", "id": "1610966488709754881"}, {"conversation_id": "1610961816326180865", "created_at": "2023-01-05T11:30:01.000Z", "public_metrics": {"retweet_count": 0, "reply_count": 0, "like_count": 0, "quote_count": 0, "impression_count": 38}, "author_id": "56126959", "text": "El #trabajo tecnológico no para: Ingeniero/a de Datos Senior @KRELL_RRHH #Madrid #MLOPs #empleo https://t.co/9TIZdGvElC", "edit_history_tweet_ids": ["1610961816326180865"], "lang": "es", "id": "1610961816326180865"}, {"conversation_id": "1610954480912154625", "created_at": "2023-01-05T11:00:52.000Z", "public_metrics": {"retweet_count": 36, "reply_count": 0, "like_count": 0, "quote_count": 0, "impression_count": 0}, "author_id": "1464631797308928009", "text": "RT @gp_pulipaka: Essential #PySpark for Scalable Data #Analytics! #BigData #DataScience #AI #MachineLearning #IoT #IIoT #Python #RStats #Te…", "edit_history_tweet_ids": ["1610954480912154625"], "lang": "en", "id": "1610954480912154625"}, {"conversation_id": "1610950753627275264", "created_at": "2023-01-05T10:46:04.000Z", "public_metrics": {"retweet_count": 2, "reply_count": 0, "like_count": 0, "quote_count": 0, "impression_count": 0}, "author_id": "262046136", "text": "RT @MitchellvRijkom: PySpark Tip ⚡ \n\nReturn the array elements from an index and specified length ✂️\n\n#PySpark #Databricks #Spark #DataEngi…", "edit_history_tweet_ids": ["1610950753627275264"], "lang": "en", "id": "1610950753627275264"}, {"conversation_id": "1610948099442343936", "created_at": "2023-01-05T10:35:31.000Z", "public_metrics": {"retweet_count": 2, "reply_count": 0, "like_count": 0, "quote_count": 0, "impression_count": 0}, "author_id": "411419084", "text": "RT @MitchellvRijkom: PySpark Tip ⚡ \n\nReturn the array elements from an index and specified length ✂️\n\n#PySpark #Databricks #Spark #DataEngi…", "edit_history_tweet_ids": ["1610948099442343936"], "lang": "en", "id": "1610948099442343936"}, {"conversation_id": "1610948073047445507", "created_at": "2023-01-05T10:35:25.000Z", "public_metrics": {"retweet_count": 2, "reply_count": 0, "like_count": 6, "quote_count": 0, "impression_count": 267}, "author_id": "719626566586744833", "text": "PySpark Tip ⚡ \n\nReturn the array elements from an index and specified length ✂️\n\n#PySpark #Databricks #Spark #DataEngineering #BigData #ETL #Programming #Python https://t.co/QI1aa24gYk", "edit_history_tweet_ids": ["1610948073047445507"], "lang": "en", "id": "1610948073047445507"}, {"conversation_id": "1610946651711246338", "created_at": "2023-01-05T10:29:46.000Z", "public_metrics": {"retweet_count": 0, "reply_count": 0, "like_count": 0, "quote_count": 0, "impression_count": 158}, "author_id": "976878157843324934", "text": "รับเขียนโปรแกรม python,pySpark,Scala\n- Data analysis \n- AI / Machine Learning / Deep learning \n- รับอธิบายงาน สอนงานผ่าน meet\n\nเรียนสาขา data science โดยตรง สามารถสอบถามราคา รายละเอียดได้ที่ไลน์หน้าไบโอค่ะ\n\n#รับทำการบ้าน #รับเขียนโค้ด #รับทําการบ้านมหาลัย #Python #รับเขียนโปรแกรม", "edit_history_tweet_ids": ["1610946651711246338"], "lang": "und", "id": "1610946651711246338"}, {"conversation_id": "1610926623121104896", "created_at": "2023-01-05T09:10:11.000Z", "public_metrics": {"retweet_count": 0, "reply_count": 0, "like_count": 0, "quote_count": 0, "impression_count": 72}, "author_id": "1533111896832102400", "text": "요즘 하는 일   AWS의 emr에서 pyspark로 데이터 처리 ….", "edit_history_tweet_ids": ["1610926623121104896"], "lang": "ko", "id": "1610926623121104896"}, {"conversation_id": "1610915764625723392", "created_at": "2023-01-05T08:27:02.000Z", "public_metrics": {"retweet_count": 0, "reply_count": 0, "like_count": 0, "quote_count": 0, "impression_count": 4}, "author_id": "1567453008107118592", "text": "To install Apache Spark and run Pyspark in Ubuntu 22.04\nHello my esteemed readers, today we will...\n#beginners #ubuntu\nhttps://t.co/AP5tmwJJPo \nhttps://t.co/AP5tmwJJPo", "edit_history_tweet_ids": ["1610915764625723392"], "lang": "en", "id": "1610915764625723392"}, {"conversation_id": "1610913222718259202", "created_at": "2023-01-05T08:16:56.000Z", "public_metrics": {"retweet_count": 0, "reply_count": 1, "like_count": 16, "quote_count": 0, "impression_count": 779}, "author_id": "1198619440272695296", "text": "The last 3 months were amazing. Learn more about pandas and pyspark. Learned Hadoop, Apache Airflow, and Github Actions. Integrated SharePoint, automated telegram and outlook emails, and learned some reactjs. 🥺🥺", "edit_history_tweet_ids": ["1610913222718259202"], "lang": "en", "id": "1610913222718259202"}], "includes": {"users": [{"created_at": "2022-06-04T15:42:41.000Z", "username": "dahlmoon99", "name": "러스트 생초보 달님", "id": "1533111896832102400"}, {"created_at": "2009-07-12T16:23:06.000Z", "username": "tecnoempleo", "name": "tecnoempleo.com", "id": "56126959"}, {"created_at": "2021-11-27T16:26:56.000Z", "username": "Rangana74599809", "name": "Ranganath", "id": "1464631797308928009"}, {"created_at": "2011-03-07T06:52:35.000Z", "username": "HereKarthiK", "name": "SUPER MAN", "id": "262046136"}, {"created_at": "2011-11-13T11:40:23.000Z", "username": "rahul05ranjan", "name": "Rahul", "id": "411419084"}, {"created_at": "2016-04-11T20:41:58.000Z", "username": "MitchellvRijkom", "name": "Mitchell van Rijkom", "id": "719626566586744833"}, {"created_at": "2018-03-22T17:47:57.000Z", "username": "wwwecool", "name": "รับเขียน Python, ML , DL 💬 แอดไลน์เท่านั้น", "id": "976878157843324934"}, {"created_at": "2022-09-07T10:01:45.000Z", "username": "prodsens_pro", "name": "ProdSens_live", "id": "1567453008107118592"}, {"created_at": "2019-11-24T15:08:48.000Z", "username": "aps08__", "name": "Anoop Pratap Singh", "id": "1198619440272695296"}]}, "meta": {"newest_id": "1610966488709754881", "oldest_id": "1610913222718259202", "result_count": 10, "next_token": "b26v89c19zqg8o3fqk3zctyu5su6o6un391qdituz7xx9"}}
{"data": [{"edit_history_tweet_ids": ["1610912309802827776"], "id": "1610912309802827776", "lang": "en", "text": "RT @gp_pulipaka: Essential #PySpark for Scalable Data #Analytics! #BigData #DataScience #AI #MachineLearning #IoT #IIoT #Python #RStats #Te…", "public_metrics": {"retweet_count": 36, "reply_count": 0, "like_count": 0, "quote_count": 0, "impression_count": 0}, "author_id": "1496310388555763714", "conversation_id": "1610912309802827776", "created_at": "2023-01-05T08:13:18.000Z"}, {"edit_history_tweet_ids": ["1610903536778223616"], "id": "1610903536778223616", "lang": "en", "text": "Dataplex — Data Processing using Custom Pyspark/Spark https://t.co/asqLpbSavp", "public_metrics": {"retweet_count": 0, "reply_count": 0, "like_count": 0, "quote_count": 0, "impression_count": 2}, "author_id": "374424111", "conversation_id": "1610903536778223616", "created_at": "2023-01-05T07:38:26.000Z"}, {"edit_history_tweet_ids": ["1610901169265840129"], "id": "1610901169265840129", "lang": "in", "text": "https://t.co/swnKX0FPQw\n\nJava Developer - MumbaiMumbai, Maharashtra\nJava Developer - PunePune, Maharashtra\nPySpark - BangaloreBengaluru, Karnataka\nPython Developer - BangaloreBengaluru, Karnataka\n\n#jobsearch #JobAlert #JobSeekers #ThursdayThoughts", "public_metrics": {"retweet_count": 0, "reply_count": 0, "like_count": 0, "quote_count": 0, "impression_count": 10}, "author_id": "1610898572102496258", "conversation_id": "1610901169265840129", "created_at": "2023-01-05T07:29:02.000Z"}, {"edit_history_tweet_ids": ["1610900870215991298"], "id": "1610900870215991298", "lang": "en", "text": "RT @gp_pulipaka: Essential #PySpark for Scalable Data #Analytics! #BigData #DataScience #AI #MachineLearning #IoT #IIoT #Python #RStats #Te…", "public_metrics": {"retweet_count": 36, "reply_count": 0, "like_count": 0, "quote_count": 0, "impression_count": 0}, "author_id": "22643279", "conversation_id": "1610900870215991298", "created_at": "2023-01-05T07:27:51.000Z"}, {"edit_history_tweet_ids": ["1610898962327683072"], "id": "1610898962327683072", "lang": "en", "text": "RT @gp_pulipaka: Essential #PySpark for Scalable Data #Analytics! #BigData #DataScience #AI #MachineLearning #IoT #IIoT #Python #RStats #Te…", "public_metrics": {"retweet_count": 36, "reply_count": 0, "like_count": 0, "quote_count": 0, "impression_count": 0}, "author_id": "2157561562", "conversation_id": "1610898962327683072", "created_at": "2023-01-05T07:20:16.000Z"}, {"edit_history_tweet_ids": ["1610890556892385284"], "id": "1610890556892385284", "lang": "en", "text": "RT @gp_pulipaka: Essential #PySpark for Scalable Data #Analytics! #BigData #DataScience #AI #MachineLearning #IoT #IIoT #Python #RStats #Te…", "public_metrics": {"retweet_count": 36, "reply_count": 0, "like_count": 0, "quote_count": 0, "impression_count": 0}, "author_id": "1565280726156804099", "conversation_id": "1610890556892385284", "created_at": "2023-01-05T06:46:52.000Z"}, {"edit_history_tweet_ids": ["1610889943118643200"], "id": "1610889943118643200", "lang": "en", "text": "RT @gp_pulipaka: Essential #PySpark for Scalable Data #Analytics! #BigData #DataScience #AI #MachineLearning #IoT #IIoT #Python #RStats #Te…", "public_metrics": {"retweet_count": 36, "reply_count": 0, "like_count": 0, "quote_count": 0, "impression_count": 0}, "author_id": "1533105519447404544", "conversation_id": "1610889943118643200", "created_at": "2023-01-05T06:44:25.000Z"}, {"edit_history_tweet_ids": ["1610889585042812929"], "id": "1610889585042812929", "lang": "en", "text": "RT @gp_pulipaka: Essential #PySpark for Scalable Data #Analytics! #BigData #DataScience #AI #MachineLearning #IoT #IIoT #Python #RStats #Te…", "public_metrics": {"retweet_count": 36, "reply_count": 0, "like_count": 0, "quote_count": 0, "impression_count": 0}, "author_id": "949311959735791616", "conversation_id": "1610889585042812929", "created_at": "2023-01-05T06:43:00.000Z"}, {"edit_history_tweet_ids": ["1610889537366130688"], "id": "1610889537366130688", "lang": "en", "text": "RT @gp_pulipaka: Essential #PySpark for Scalable Data #Analytics! #BigData #DataScience #AI #MachineLearning #IoT #IIoT #Python #RStats #Te…", "public_metrics": {"retweet_count": 36, "reply_count": 0, "like_count": 0, "quote_count": 0, "impression_count": 0}, "author_id": "4908885163", "conversation_id": "1610889537366130688", "created_at": "2023-01-05T06:42:49.000Z"}, {"edit_history_tweet_ids": ["1610889347384893441"], "id": "1610889347384893441", "lang": "en", "text": "RT @gp_pulipaka: Essential #PySpark for Scalable Data #Analytics! #BigData #DataScience #AI #MachineLearning #IoT #IIoT #Python #RStats #Te…", "public_metrics": {"retweet_count": 36, "reply_count": 0, "like_count": 0, "quote_count": 0, "impression_count": 0}, "author_id": "709564705304498176", "conversation_id": "1610889347384893441", "created_at": "2023-01-05T06:42:03.000Z"}], "includes": {"users": [{"id": "1496310388555763714", "username": "DomingoDeDia1", "created_at": "2022-02-23T02:26:27.000Z", "name": "Domingo De Dia"}, {"id": "374424111", "username": "grassycarl", "created_at": "2011-09-16T09:03:06.000Z", "name": "Carl Tanner"}, {"id": "1610898572102496258", "username": "Chags2Chags", "created_at": "2023-01-05T07:18:53.000Z", "name": "Chags"}, {"id": "22643279", "username": "gdsttian", "created_at": "2009-03-03T16:43:31.000Z", "name": "T Tian"}, {"id": "2157561562", "username": "AlbertBIKELE", "created_at": "2013-10-28T18:41:25.000Z", "name": "Albert BIKELE"}, {"id": "1565280726156804099", "username": "sdogdev", "created_at": "2022-09-01T10:10:53.000Z", "name": "SkandogDev"}, {"id": "1533105519447404544", "username": "PythonBot_By_PM", "created_at": "2022-06-04T15:19:08.000Z", "name": "PyBot"}, {"id": "949311959735791616", "username": "RaymondWSA460", "created_at": "2018-01-05T16:09:43.000Z", "name": "Raymond460"}, {"id": "4908885163", "username": "DeepSingularity", "created_at": "2016-02-15T00:04:06.000Z", "name": "DeepSingularity LLC"}, {"id": "709564705304498176", "username": "Calcaware", "created_at": "2016-03-15T02:19:43.000Z", "name": "Christopher Burnette"}]}, "meta": {"newest_id": "1610912309802827776", "oldest_id": "1610889347384893441", "result_count": 10, "next_token": "b26v89c19zqg8o3fqk3zcrw7skg9muwmmnua7hu48ahz1"}}
{"data": [{"lang": "en", "created_at": "2023-01-05T06:42:01.000Z", "public_metrics": {"retweet_count": 36, "reply_count": 0, "like_count": 80, "quote_count": 0, "impression_count": 6265}, "text": "Essential #PySpark for Scalable Data #Analytics! #BigData #DataScience #AI #MachineLearning #IoT #IIoT #Python #RStats #TensorFlow #Java #JavaScript #ReactJS #CloudComputing #Serverless #DataScientist #Linux #Books #Programming #Coding #100DaysofCode \nhttps://t.co/4JDUE7CbLd https://t.co/M23ZBC8rvm", "conversation_id": "1610889336861360130", "edit_history_tweet_ids": ["1610889336861360130"], "id": "1610889336861360130", "author_id": "4263007693"}, {"lang": "en", "created_at": "2023-01-05T06:30:22.000Z", "public_metrics": {"retweet_count": 0, "reply_count": 0, "like_count": 3, "quote_count": 0, "impression_count": 191}, "text": "@ponderdata Pandas api on spark or move pyspark dataframes", "conversation_id": "1610682537189281797", "in_reply_to_user_id": "1409999723784671234", "edit_history_tweet_ids": ["1610886403432542208"], "id": "1610886403432542208", "author_id": "20433419"}, {"lang": "en", "created_at": "2023-01-05T05:57:54.000Z", "public_metrics": {"retweet_count": 0, "reply_count": 0, "like_count": 0, "quote_count": 0, "impression_count": 1}, "text": "@AWSCharityJobs we are hiring for AWS Paas Services consultant who is having experience with aws glie and Pyspark,having 6 +years experience,if interested kindly ping me on 9908425977", "conversation_id": "1610878235436539904", "in_reply_to_user_id": "4235329223", "edit_history_tweet_ids": ["1610878235436539904"], "id": "1610878235436539904", "author_id": "1300012188"}, {"lang": "en", "created_at": "2023-01-05T05:44:27.000Z", "public_metrics": {"retweet_count": 6, "reply_count": 0, "like_count": 0, "quote_count": 0, "impression_count": 0}, "text": "RT @databricks: It’s time to optimize 📈 PySpark UDFs and reduce ⬇️ the likelihood of out-of-memory errors.\n\nLearn how the PySpark memory pr…", "conversation_id": "1610874851136241665", "edit_history_tweet_ids": ["1610874851136241665"], "id": "1610874851136241665", "author_id": "480875170"}, {"lang": "en", "created_at": "2023-01-05T05:16:52.000Z", "public_metrics": {"retweet_count": 0, "reply_count": 0, "like_count": 0, "quote_count": 0, "impression_count": 2}, "text": "Dataplex — Data Processing using Custom Pyspark/Spark https://t.co/Zi5U4FSJd8", "conversation_id": "1610867906866208769", "edit_history_tweet_ids": ["1610867906866208769"], "id": "1610867906866208769", "author_id": "1241726197072977921"}, {"lang": "en", "created_at": "2023-01-05T03:07:23.000Z", "public_metrics": {"retweet_count": 0, "reply_count": 0, "like_count": 1, "quote_count": 0, "impression_count": 14}, "text": "This is extremely compelling; I’ve had to go back and forth between #Pandas DFs and #PySpark DFs in many contexts, and the subtle differences in the respective #API for each is an unpleasant experience.", "conversation_id": "1608303737294012416", "in_reply_to_user_id": "1505359964373671936", "edit_history_tweet_ids": ["1610835320974491652"], "id": "1610835320974491652", "author_id": "1505359964373671936"}, {"lang": "en", "created_at": "2023-01-05T03:07:21.000Z", "public_metrics": {"retweet_count": 0, "reply_count": 1, "like_count": 0, "quote_count": 0, "impression_count": 12}, "text": "These are things that I have used #PySpark (and #ApacheAirflow) to address in the past. Looking forward to comparing that to how #Dask works.", "conversation_id": "1608303737294012416", "in_reply_to_user_id": "1505359964373671936", "edit_history_tweet_ids": ["1610835313538269188"], "id": "1610835313538269188", "author_id": "1505359964373671936"}, {"lang": "en", "created_at": "2023-01-05T01:52:50.000Z", "public_metrics": {"retweet_count": 6, "reply_count": 0, "like_count": 0, "quote_count": 0, "impression_count": 0}, "text": "RT @databricks: It’s time to optimize 📈 PySpark UDFs and reduce ⬇️ the likelihood of out-of-memory errors.\n\nLearn how the PySpark memory pr…", "conversation_id": "1610816562105307138", "edit_history_tweet_ids": ["1610816562105307138"], "id": "1610816562105307138", "author_id": "741274134181601280"}, {"lang": "en", "created_at": "2023-01-05T01:31:01.000Z", "public_metrics": {"retweet_count": 0, "reply_count": 0, "like_count": 0, "quote_count": 0, "impression_count": 44}, "text": "Change Healthcare is looking for a Software Engineer - Payment Integrity - Python -C#.Net  - SQL - Big Data - PySpark - AWS - REMOTE POSITION\nhttps://t.co/GaBQioexk7 Columbus, OH, United States\n( CSharp  Python  Cloud  MongoDB ) \n#nowhiring #MongoDB", "conversation_id": "1610811072683950087", "edit_history_tweet_ids": ["1610811072683950087"], "id": "1610811072683950087", "author_id": "1463094498779537414"}, {"lang": "en", "created_at": "2023-01-05T01:31:01.000Z", "public_metrics": {"retweet_count": 0, "reply_count": 0, "like_count": 0, "quote_count": 0, "impression_count": 24}, "text": "Change Healthcare is looking for a Software Engineer - Payment Integrity - Python -C#. - .Net - Clustering - Microservices - SQL - Big Data pipelines. - PySpark - Python - AWS\nhttps://t.co/MQsOnrowaf Atlanta, GA, United States\n( CSharp  Python  Cloud ) \n#careers #Cloud", "conversation_id": "1610811070565781504", "edit_history_tweet_ids": ["1610811070565781504"], "id": "1610811070565781504", "author_id": "1463094498779537414"}], "includes": {"users": [{"created_at": "2015-11-17T02:19:09.000Z", "username": "gp_pulipaka", "id": "4263007693", "name": "Dr. Ganapathi Pulipaka 🇺🇸"}, {"created_at": "2009-02-09T13:06:24.000Z", "username": "pradeep5338", "id": "20433419", "name": "Pradeep Jain"}, {"created_at": "2013-03-25T15:55:23.000Z", "username": "etinku1992", "id": "1300012188", "name": "ENK"}, {"created_at": "2012-02-02T01:05:50.000Z", "username": "VonRosenchild", "id": "480875170", "name": "VonVictor Valentino Rosenchild"}, {"created_at": "2020-03-22T13:59:37.000Z", "username": "Rajput2020S", "id": "1241726197072977921", "name": "SRajput2020"}, {"created_at": "2022-03-20T01:47:05.000Z", "username": "dlchet", "id": "1505359964373671936", "name": "Dan Chetlin"}, {"created_at": "2016-06-10T14:21:40.000Z", "username": "chersmilesabit", "id": "741274134181601280", "name": "Cheryl Miles"}, {"created_at": "2021-11-23T10:55:52.000Z", "username": "PythonJobsFeed", "id": "1463094498779537414", "name": "Python Jobs feed"}]}, "meta": {"newest_id": "1610889336861360130", "oldest_id": "1610811070565781504", "result_count": 10, "next_token": "b26v89c19zqg8o3fqk3zcru3xf7jyvrcewk9n970rx27x"}}
{"data": [{"id": "1610807883595415553", "author_id": "1255452976673697797", "edit_history_tweet_ids": ["1610807883595415553"], "public_metrics": {"retweet_count": 0, "reply_count": 0, "like_count": 0, "quote_count": 0, "impression_count": 47}, "conversation_id": "1610807883595415553", "text": "🙂 Deepgram is hiring a remote Lead Data Engineer #Deepgram #remotework #remotejob #workfromhome #DataInfrastructure #NoSQL #SQL #DistributedSystems #Python #Pyspark #Spark #Hadoop https://t.co/PGWTnGotWJ", "lang": "en", "created_at": "2023-01-05T01:18:21.000Z"}, {"id": "1610794604734849025", "author_id": "1490810776344485891", "edit_history_tweet_ids": ["1610794604734849025"], "public_metrics": {"retweet_count": 0, "reply_count": 0, "like_count": 0, "quote_count": 0, "impression_count": 0}, "conversation_id": "1610794604734849025", "text": "Dataplex — Data Processing using Custom Pyspark/Spark https://t.co/IkrRCh6OZk", "lang": "en", "created_at": "2023-01-05T00:25:35.000Z"}], "includes": {"users": [{"username": "himalayasapp", "name": "Himalayas", "id": "1255452976673697797", "created_at": "2020-04-29T11:05:00.000Z"}, {"username": "LuisAlb92109432", "name": "Luis Alberto Zerón López", "id": "1490810776344485891", "created_at": "2022-02-07T22:13:05.000Z"}]}, "meta": {"newest_id": "1610807883595415553", "oldest_id": "1610794604734849025", "result_count": 2}}
