{"data": [{"edit_history_tweet_ids": ["1611512066807832577"], "lang": "en", "public_metrics": {"retweet_count": 0, "reply_count": 0, "like_count": 0, "quote_count": 0, "impression_count": 91}, "created_at": "2023-01-06T23:56:31.000Z", "id": "1611512066807832577", "conversation_id": "1611512066807832577", "text": "I am in an abusive relationship with PySparküò≠üò≠üò≠", "author_id": "548810401"}, {"edit_history_tweet_ids": ["1611511894891692033"], "lang": "en", "public_metrics": {"retweet_count": 0, "reply_count": 0, "like_count": 0, "quote_count": 0, "impression_count": 59}, "created_at": "2023-01-06T23:55:50.000Z", "id": "1611511894891692033", "conversation_id": "1611467726001786888", "in_reply_to_user_id": "103961836", "text": "@__mharrison__ I don't like PySpark üò≠üò≠üò≠", "author_id": "548810401"}, {"edit_history_tweet_ids": ["1611507843412393984"], "lang": "en", "public_metrics": {"retweet_count": 0, "reply_count": 0, "like_count": 0, "quote_count": 0, "impression_count": 294}, "created_at": "2023-01-06T23:39:44.000Z", "id": "1611507843412393984", "conversation_id": "1611455782792339468", "in_reply_to_user_id": "19304217", "text": "@vboykis 100% - I maintain cheatsheets for all the tools/languages (git, trino, pyspark) I use and are the most visited and useful pages for me.", "author_id": "168767599"}, {"edit_history_tweet_ids": ["1611499256245886976"], "lang": "en", "public_metrics": {"retweet_count": 3, "reply_count": 0, "like_count": 0, "quote_count": 0, "impression_count": 0}, "created_at": "2023-01-06T23:05:37.000Z", "id": "1611499256245886976", "conversation_id": "1611499256245886976", "text": "RT @CologneAIML: We have updated the details for our event on January 25 üéâ To learn more about our speakers and talks, and to register for‚Ä¶", "author_id": "998858703347462149"}, {"edit_history_tweet_ids": ["1611494775882158080"], "lang": "ja", "public_metrics": {"retweet_count": 0, "reply_count": 0, "like_count": 0, "quote_count": 0, "impression_count": 91}, "created_at": "2023-01-06T22:47:49.000Z", "id": "1611494775882158080", "conversation_id": "1611494775882158080", "text": "„Éá„Éº„Çø„Çµ„Ç§„Ç®„É≥„Çπ100Êú¨„Éé„ÉÉ„ÇØ(ÊßãÈÄ†Âåñ„Éá„Éº„ÇøÂä†Â∑•Á∑®)„ÅÆPySparkÁâà„Çí‰Ωú„Å£„Å¶„ÅÑ„Åæ„Åô„ÄÇScala„Å®PySpark„ÅÆ„Ç≥„Éº„Éâ„ÅØ„Åª„Å®„Çì„Å©Âêå„Åò„Å™„ÅÆ„Åß„ÄÅScala„ÅßËß£„ÅÑ„Å¶„ÅÑ„Çå„Å∞PySpark„Å´Á∞°Âçò„Å´Â§âÊèõ„Åß„Åç„Åù„ÅÜ„Åß„Åô„ÄÇ„Å°„Å™„Åø„Å´ÂÆüË°åÁµêÊûú„Çí„Éâ„Ç≠„É•„É°„É≥„ÉàÂåñ„Åô„ÇãÁí∞Â¢É„ÅØ„ÄÅR Markdown + reticulate „Åß„Åô„ÄÇ", "author_id": "856810445721743361"}, {"edit_history_tweet_ids": ["1611482669463883796"], "lang": "en", "public_metrics": {"retweet_count": 3, "reply_count": 0, "like_count": 0, "quote_count": 0, "impression_count": 0}, "created_at": "2023-01-06T21:59:42.000Z", "id": "1611482669463883796", "conversation_id": "1611482669463883796", "text": "RT @CologneAIML: We have updated the details for our event on January 25 üéâ To learn more about our speakers and talks, and to register for‚Ä¶", "author_id": "292909175"}, {"edit_history_tweet_ids": ["1611478874759614487"], "lang": "en", "public_metrics": {"retweet_count": 0, "reply_count": 0, "like_count": 0, "quote_count": 0, "impression_count": 15}, "created_at": "2023-01-06T21:44:38.000Z", "id": "1611478874759614487", "conversation_id": "1611478874759614487", "text": "We shared a new blog on BI-FI BLOGS : Learn DataBricks PySpark &amp; SparkSQL with our Notebook\n\nCheck it out via link below :\nhttps://t.co/HFVizsdVJj\n\n#bifiblogs #lowcode #python #databricks #sql #powerbi\n#dataanalytics #knime #vba", "author_id": "1610318564753346561"}, {"edit_history_tweet_ids": ["1611478870674362374"], "lang": "en", "public_metrics": {"retweet_count": 0, "reply_count": 0, "like_count": 0, "quote_count": 0, "impression_count": 13}, "created_at": "2023-01-06T21:44:37.000Z", "id": "1611478870674362374", "conversation_id": "1611478870674362374", "text": "We shared a new blog on BI-FI BLOGS : How to create Delta Tables from Pyspark Dataframes\n\nCheck it out via link below :\nhttps://t.co/VsgGwPyGQI\n\n#bifiblogs #lowcode #python #databricks #sql #powerbi\n#dataanalytics #knime #vba", "author_id": "1610318564753346561"}, {"edit_history_tweet_ids": ["1611478868610764814"], "lang": "en", "public_metrics": {"retweet_count": 0, "reply_count": 0, "like_count": 0, "quote_count": 0, "impression_count": 13}, "created_at": "2023-01-06T21:44:36.000Z", "id": "1611478868610764814", "conversation_id": "1611478868610764814", "text": "We shared a new blog on BI-FI BLOGS : How to Use SQL Queries in Pyspark\n\nCheck it out via link below :\nhttps://t.co/82nPuICsuA\n\n#bifiblogs #lowcode #python #databricks #sql #powerbi\n#dataanalytics #knime #vba", "author_id": "1610318564753346561"}, {"edit_history_tweet_ids": ["1611478867276976155"], "lang": "en", "public_metrics": {"retweet_count": 0, "reply_count": 0, "like_count": 0, "quote_count": 0, "impression_count": 11}, "created_at": "2023-01-06T21:44:36.000Z", "id": "1611478867276976155", "conversation_id": "1611478867276976155", "text": "We shared a new blog on BI-FI BLOGS : Handling Missing Values with Pyspark\n\nCheck it out via link below :\nhttps://t.co/AnH3HT7QYe\n\n#bifiblogs #lowcode #python #databricks #sql #powerbi\n#dataanalytics #knime #vba", "author_id": "1610318564753346561"}], "includes": {"users": [{"username": "phesirius", "name": "Oluwafemi", "id": "548810401", "created_at": "2012-04-09T00:07:43.000Z"}, {"username": "CausalSandeep", "name": "Sandeep Gangarapu", "id": "168767599", "created_at": "2010-07-20T19:16:41.000Z"}, {"username": "YohaneesH", "name": "Y H", "id": "998858703347462149", "created_at": "2018-05-22T09:30:47.000Z"}, {"username": "cppfriendsbot", "name": "R„Åü„ÇìüéÄ", "id": "856810445721743361", "created_at": "2017-04-25T10:01:43.000Z"}, {"username": "MM2de", "name": "Marc M√ºller", "id": "292909175", "created_at": "2011-05-04T12:55:47.000Z"}, {"username": "bifi_blog", "name": "BI-FI BLOGS", "id": "1610318564753346561", "created_at": "2023-01-03T16:54:11.000Z"}]}, "meta": {"newest_id": "1611512066807832577", "oldest_id": "1611478867276976155", "result_count": 10, "next_token": "b26v89c19zqg8o3fqk3zroyyadofgocxptxc81iuhi5j1"}}
{"data": [{"lang": "en", "author_id": "1610318564753346561", "created_at": "2023-01-06T21:44:35.000Z", "text": "We shared a new blog on BI-FI BLOGS : Handling Duplicates with Pyspark\n\nCheck it out via link below :\nhttps://t.co/TV3SegsL9Z\n\n#bifiblogs #lowcode #python #databricks #sql #powerbi\n#dataanalytics #knime #vba", "id": "1611478863053209601", "conversation_id": "1611478863053209601", "public_metrics": {"retweet_count": 0, "reply_count": 0, "like_count": 0, "quote_count": 0, "impression_count": 9}, "edit_history_tweet_ids": ["1611478863053209601"]}, {"lang": "en", "author_id": "1135158162", "created_at": "2023-01-06T19:50:18.000Z", "text": "RT @CologneAIML: We have updated the details for our event on January 25 üéâ To learn more about our speakers and talks, and to register for‚Ä¶", "id": "1611450101007794176", "conversation_id": "1611450101007794176", "public_metrics": {"retweet_count": 3, "reply_count": 0, "like_count": 0, "quote_count": 0, "impression_count": 0}, "edit_history_tweet_ids": ["1611450101007794176"]}, {"lang": "en", "author_id": "1006536730403639297", "created_at": "2023-01-06T19:17:40.000Z", "text": "We have updated the details for our event on January 25 üéâ To learn more about our speakers and talks, and to register for the event, visit https://t.co/J35Ibh5nvf\n#CAIML #MachineLearning #SageMaker #SPLINK #PySpark", "id": "1611441892155133979", "conversation_id": "1611441892155133979", "public_metrics": {"retweet_count": 3, "reply_count": 0, "like_count": 3, "quote_count": 0, "impression_count": 108}, "edit_history_tweet_ids": ["1611441892155133979"]}, {"lang": "en", "author_id": "1577882062727413760", "created_at": "2023-01-06T19:11:11.000Z", "text": "RT @ripulchhabra: Day 50 | PySpark | Spark Streaming | Tumbling Window\n\n#python3\n#100DaysOfCode \n#100daysofcodechallenge \n#BigData \n#spark‚Ä¶", "id": "1611440258716995592", "conversation_id": "1611440258716995592", "public_metrics": {"retweet_count": 2, "reply_count": 0, "like_count": 0, "quote_count": 0, "impression_count": 0}, "edit_history_tweet_ids": ["1611440258716995592"]}, {"lang": "en", "author_id": "1551060443040325632", "created_at": "2023-01-06T19:10:16.000Z", "text": "RT @ripulchhabra: Day 50 | PySpark | Spark Streaming | Tumbling Window\n\n#python3\n#100DaysOfCode \n#100daysofcodechallenge \n#BigData \n#spark‚Ä¶", "id": "1611440030152798208", "conversation_id": "1611440030152798208", "public_metrics": {"retweet_count": 2, "reply_count": 0, "like_count": 0, "quote_count": 0, "impression_count": 0}, "edit_history_tweet_ids": ["1611440030152798208"]}, {"lang": "en", "author_id": "282513414", "created_at": "2023-01-06T19:09:37.000Z", "text": "Day 50 | PySpark | Spark Streaming | Tumbling Window\n\n#python3\n#100DaysOfCode \n#100daysofcodechallenge \n#BigData \n#spark \n#Python", "id": "1611439865681575936", "conversation_id": "1611439865681575936", "public_metrics": {"retweet_count": 2, "reply_count": 0, "like_count": 4, "quote_count": 0, "impression_count": 30}, "edit_history_tweet_ids": ["1611439865681575936"]}, {"lang": "en", "author_id": "710123736175783938", "created_at": "2023-01-06T19:00:56.000Z", "text": "RT @gp_pulipaka: Essential #PySpark for Scalable Data #Analytics! #BigData #DataScience #AI #MachineLearning #IoT #IIoT #Python #RStats #Te‚Ä¶", "id": "1611437680360816641", "conversation_id": "1611437680360816641", "public_metrics": {"retweet_count": 36, "reply_count": 0, "like_count": 0, "quote_count": 0, "impression_count": 0}, "edit_history_tweet_ids": ["1611437680360816641"]}, {"lang": "en", "author_id": "1541619539930120193", "created_at": "2023-01-06T19:00:55.000Z", "text": "RT @gp_pulipaka: Essential #PySpark for Scalable Data #Analytics! #BigData #DataScience #AI #MachineLearning #IoT #IIoT #Python #RStats #Te‚Ä¶", "id": "1611437674967060481", "conversation_id": "1611437674967060481", "public_metrics": {"retweet_count": 36, "reply_count": 0, "like_count": 0, "quote_count": 0, "impression_count": 0}, "edit_history_tweet_ids": ["1611437674967060481"]}, {"lang": "en", "author_id": "290599254", "created_at": "2023-01-06T18:48:19.000Z", "text": "Dataplex ‚Äî Data Processing using Custom Pyspark/Spark https://t.co/DsiiIhavHD", "id": "1611434504756858887", "conversation_id": "1611434504756858887", "public_metrics": {"retweet_count": 0, "reply_count": 0, "like_count": 0, "quote_count": 0, "impression_count": 57}, "edit_history_tweet_ids": ["1611434504756858887"]}, {"lang": "und", "author_id": "802566655142461440", "created_at": "2023-01-06T16:57:32.000Z", "text": "@Pyspark_2 @CinemaWithAB üòÇüòÇ", "id": "1611406625159671809", "conversation_id": "1611391101625339906", "public_metrics": {"retweet_count": 0, "reply_count": 0, "like_count": 0, "quote_count": 0, "impression_count": 27}, "edit_history_tweet_ids": ["1611406625159671809"], "in_reply_to_user_id": "1198169498802515968"}], "includes": {"users": [{"name": "BI-FI BLOGS", "username": "bifi_blog", "id": "1610318564753346561", "created_at": "2023-01-03T16:54:11.000Z"}, {"name": "Robin Linacre", "username": "RobinLinacre", "id": "1135158162", "created_at": "2013-01-30T20:48:23.000Z"}, {"name": "CologneAIML", "username": "CologneAIML", "id": "1006536730403639297", "created_at": "2018-06-12T14:00:31.000Z"}, {"name": "py_twt", "username": "pytwt3", "id": "1577882062727413760", "created_at": "2022-10-06T04:42:58.000Z"}, {"name": "üß∏ Bot", "username": "TeddyBearIsABot", "id": "1551060443040325632", "created_at": "2022-07-24T04:23:27.000Z"}, {"name": "Ripul Chhabra", "username": "ripulchhabra", "id": "282513414", "created_at": "2011-04-15T10:39:29.000Z"}, {"name": "Security News", "username": "sectest9", "id": "710123736175783938", "created_at": "2016-03-16T15:21:07.000Z"}, {"name": "Stefani Colossi", "username": "Dear__Stefani", "id": "1541619539930120193", "created_at": "2022-06-28T03:09:57.000Z"}, {"name": "Lucas Magnum", "username": "LucasMagn", "id": "290599254", "created_at": "2011-04-30T15:18:51.000Z"}, {"name": "karthik", "username": "Karthik19351532", "id": "802566655142461440", "created_at": "2016-11-26T17:36:16.000Z"}]}, "meta": {"newest_id": "1611478863053209601", "oldest_id": "1611406625159671809", "result_count": 10, "next_token": "b26v89c19zqg8o3fqk3zrowuocdnslx6bm6xcgb0z7rel"}}
{"data": [{"edit_history_tweet_ids": ["1611402030693629960"], "lang": "en", "public_metrics": {"retweet_count": 3, "reply_count": 0, "like_count": 0, "quote_count": 0, "impression_count": 0}, "created_at": "2023-01-06T16:39:17.000Z", "id": "1611402030693629960", "conversation_id": "1611402030693629960", "text": "RT @MitchellvRijkom: PySpark Tip ‚ö°\n\nSelect the latest record from a sequence when rows have the same ID.\n\nSo you can work only with the mos‚Ä¶", "author_id": "1208985402754945024"}, {"edit_history_tweet_ids": ["1611399996535881732"], "lang": "fr", "public_metrics": {"retweet_count": 0, "reply_count": 0, "like_count": 0, "quote_count": 0, "impression_count": 7}, "created_at": "2023-01-06T16:31:12.000Z", "id": "1611399996535881732", "conversation_id": "1611399996535881732", "text": "#pyspark #spark #BigData curso completo de Python y Spark con PySpark\n\nhttps://t.co/3MLFZp9AaX", "author_id": "829402214024216577"}, {"edit_history_tweet_ids": ["1611381276224720897"], "lang": "en", "public_metrics": {"retweet_count": 0, "reply_count": 0, "like_count": 1, "quote_count": 0, "impression_count": 6}, "created_at": "2023-01-06T15:16:48.000Z", "id": "1611381276224720897", "conversation_id": "1611015994000003075", "in_reply_to_user_id": "446971586", "text": "@verci_eth It depends on what do you want.\n\nVaex is more memory efficient.\nDask/PySpark are more efficient with parallel and cloud computing.\n\nI'll do more threads about these libraries", "author_id": "1575954402988494848"}, {"edit_history_tweet_ids": ["1611378480524165121"], "lang": "en", "public_metrics": {"retweet_count": 0, "reply_count": 1, "like_count": 6, "quote_count": 0, "impression_count": 232}, "created_at": "2023-01-06T15:05:42.000Z", "id": "1611378480524165121", "conversation_id": "1611378480524165121", "text": "D10 | #100daysofcoding finally finished my AWS Glue PySpark script that will keep my parquet s3 bucket up to date.", "author_id": "796346808167448576"}, {"edit_history_tweet_ids": ["1611362584208486400"], "lang": "en", "public_metrics": {"retweet_count": 0, "reply_count": 1, "like_count": 5, "quote_count": 0, "impression_count": 0}, "created_at": "2023-01-06T14:02:32.000Z", "id": "1611362584208486400", "conversation_id": "1611362584208486400", "text": "Encrypt the email IDs using PySpark.\nFor this we use aes_encrypt and aes_decrypt functions.\n\n‚úçÔ∏è Article link:-  https://t.co/EkavxziEHQ https://t.co/tXInYNYxoK", "author_id": "1272409948555587585"}, {"edit_history_tweet_ids": ["1611357495146037249"], "lang": "en", "public_metrics": {"retweet_count": 0, "reply_count": 0, "like_count": 0, "quote_count": 0, "impression_count": 1}, "created_at": "2023-01-06T13:42:19.000Z", "id": "1611357495146037249", "conversation_id": "1611357495146037249", "text": "Dataplex ‚Äî Data Processing using Custom Pyspark/Spark https://t.co/r9fQOHhOAg", "author_id": "953041002037727232"}, {"edit_history_tweet_ids": ["1611351071376515072"], "lang": "en", "public_metrics": {"retweet_count": 2, "reply_count": 0, "like_count": 0, "quote_count": 0, "impression_count": 0}, "created_at": "2023-01-06T13:16:47.000Z", "id": "1611351071376515072", "conversation_id": "1611351071376515072", "text": "RT @databricks: üëã Say \"hello\" to transpiler, a Databricks Labs open-source project that automates the translation of Splunk SPL queries int‚Ä¶", "author_id": "2742938653"}, {"edit_history_tweet_ids": ["1611320179920891907"], "lang": "en", "public_metrics": {"retweet_count": 0, "reply_count": 0, "like_count": 2, "quote_count": 0, "impression_count": 18}, "created_at": "2023-01-06T11:14:02.000Z", "id": "1611320179920891907", "conversation_id": "1611320176846462976", "in_reply_to_user_id": "1300327537495519235", "text": "For cache, the default storage level is memory only; for persist, we can pass a parameter to select storage level, such as Memory_only/Disk_only.\nhere is how we can use them in pyspark code https://t.co/5qh65SK7sj", "author_id": "1300327537495519235"}, {"edit_history_tweet_ids": ["1611314541035663361"], "lang": "en", "public_metrics": {"retweet_count": 37, "reply_count": 0, "like_count": 0, "quote_count": 0, "impression_count": 0}, "created_at": "2023-01-06T10:51:38.000Z", "id": "1611314541035663361", "conversation_id": "1611314541035663361", "text": "RT @gp_pulipaka: Learn #PySpark! #BigData #Analytics #DataScience #AI #MachineLearning #IoT #IIoT #PyTorch #Python #RStats #TensorFlow #Jav‚Ä¶", "author_id": "1371075909726375936"}, {"edit_history_tweet_ids": ["1611312127293419525"], "lang": "en", "public_metrics": {"retweet_count": 36, "reply_count": 0, "like_count": 0, "quote_count": 0, "impression_count": 0}, "created_at": "2023-01-06T10:42:02.000Z", "id": "1611312127293419525", "conversation_id": "1611312127293419525", "text": "RT @gp_pulipaka: Essential #PySpark for Scalable Data #Analytics! #BigData #DataScience #AI #MachineLearning #IoT #IIoT #Python #RStats #Te‚Ä¶", "author_id": "1371075909726375936"}], "includes": {"users": [{"username": "magic_in_music7", "name": "SASA", "id": "1208985402754945024", "created_at": "2019-12-23T05:39:26.000Z"}, {"username": "JosMiguelMoya1", "name": "Jos√© Miguel Moya", "id": "829402214024216577", "created_at": "2017-02-08T18:51:12.000Z"}, {"username": "SanxRoz", "name": "Santiago", "id": "1575954402988494848", "created_at": "2022-09-30T21:03:18.000Z"}, {"username": "jegajardog", "name": "Juan Gajardo", "id": "796346808167448576", "created_at": "2016-11-09T13:40:49.000Z"}, {"username": "kishan_py", "name": "Kishan | Data Engineer", "id": "1272409948555587585", "created_at": "2020-06-15T06:06:22.000Z"}, {"username": "ccermeli2", "name": "Claudia Cermeli", "id": "953041002037727232", "created_at": "2018-01-15T23:07:36.000Z"}, {"username": "HubBucket", "name": "HubBucket Inc | Discovery Invention and Innovation", "id": "2742938653", "created_at": "2014-08-18T19:53:23.000Z"}, {"username": "SoodKaushal", "name": "Kaushal Sood", "id": "1300327537495519235", "created_at": "2020-08-31T07:00:33.000Z"}, {"username": "ResearchGuru6", "name": "Research Guru", "id": "1371075909726375936", "created_at": "2021-03-14T12:29:21.000Z"}]}, "meta": {"newest_id": "1611402030693629960", "oldest_id": "1611312127293419525", "result_count": 10, "next_token": "b26v89c19zqg8o3fqk3zrmsf5c8i9cbmv2p1sm3mwioot"}}
{"data": [{"edit_history_tweet_ids": ["1611309217595392000"], "id": "1611309217595392000", "lang": "en", "text": "Dataplex ‚Äî Data Processing using Custom Pyspark/Spark https://t.co/alExrcFRaE", "public_metrics": {"retweet_count": 0, "reply_count": 0, "like_count": 0, "quote_count": 0, "impression_count": 4}, "author_id": "46761170", "conversation_id": "1611309217595392000", "created_at": "2023-01-06T10:30:28.000Z"}, {"edit_history_tweet_ids": ["1611306415595094020"], "id": "1611306415595094020", "in_reply_to_user_id": "1411245512980787203", "lang": "en", "text": "Find nine of the newsletters with Machine Learning best practices.\n\nIn the upcoming newsletter, I will be publishing imputation with pyspark. https://t.co/RpEyZE4LMb", "public_metrics": {"retweet_count": 0, "reply_count": 0, "like_count": 1, "quote_count": 0, "impression_count": 195}, "author_id": "1411245512980787203", "conversation_id": "1611306412961071104", "created_at": "2023-01-06T10:19:20.000Z"}, {"edit_history_tweet_ids": ["1611283698992939013"], "id": "1611283698992939013", "lang": "en", "text": "#dataengineering #data Get started with PySpark on Jupyter Notebook: 3 easy steps https://t.co/V91D4VfeYL", "public_metrics": {"retweet_count": 0, "reply_count": 0, "like_count": 0, "quote_count": 0, "impression_count": 5}, "author_id": "1167839853184258049", "conversation_id": "1611283698992939013", "created_at": "2023-01-06T08:49:04.000Z"}, {"edit_history_tweet_ids": ["1611248735362715649"], "id": "1611248735362715649", "lang": "en", "text": "Join the DataHour tonight at 8:30 PM by Rishabh Agarwal (Data Engineer at McKinsey &amp; Company) and find out how to transform data using PySpark ‚ú®. https://t.co/52f8czyb4W https://t.co/bxC0Ll3mfz", "public_metrics": {"retweet_count": 0, "reply_count": 0, "like_count": 0, "quote_count": 0, "impression_count": 638}, "author_id": "2311645130", "conversation_id": "1611248735362715649", "created_at": "2023-01-06T06:30:08.000Z"}, {"edit_history_tweet_ids": ["1611245263368380418"], "id": "1611245263368380418", "lang": "de", "text": "[BUG] PySpark version is still 3.3.0 in master https://t.co/bvht0xVzL0 #github #Scala #Python #Java #Shell #HCL #ANTLR #Dockerfile", "public_metrics": {"retweet_count": 0, "reply_count": 0, "like_count": 1, "quote_count": 0, "impression_count": 19}, "author_id": "1078992647933448192", "conversation_id": "1611245263368380418", "created_at": "2023-01-06T06:16:20.000Z"}, {"edit_history_tweet_ids": ["1611238264974852096"], "id": "1611238264974852096", "lang": "en", "text": "RT @gp_pulipaka: Essential #PySpark for Scalable Data #Analytics! #BigData #DataScience #AI #MachineLearning #IoT #IIoT #Python #RStats #Te‚Ä¶", "public_metrics": {"retweet_count": 36, "reply_count": 0, "like_count": 0, "quote_count": 0, "impression_count": 0}, "author_id": "527397291", "conversation_id": "1611238264974852096", "created_at": "2023-01-06T05:48:32.000Z"}, {"edit_history_tweet_ids": ["1611212463512457218"], "id": "1611212463512457218", "lang": "en", "text": "RT @gp_pulipaka: Essential #PySpark for Scalable Data #Analytics! #BigData #DataScience #AI #MachineLearning #IoT #IIoT #Python #RStats #Te‚Ä¶", "public_metrics": {"retweet_count": 36, "reply_count": 0, "like_count": 0, "quote_count": 0, "impression_count": 0}, "author_id": "766431397", "conversation_id": "1611212463512457218", "created_at": "2023-01-06T04:06:00.000Z"}, {"edit_history_tweet_ids": ["1611211427372765185"], "id": "1611211427372765185", "lang": "ja", "text": "$PLTR „Éã„É•„Éº„Ç∏„É£„Éº„Ç∏„ÉºÂ∑û„ÅÆ„ÇΩ„Éï„Éà„Ç¶„Çß„Ç¢ÈñãÁô∫‰ºÅÊ•≠Smart IT Frame LLC„ÅØ„ÄÅAWSÁí∞Â¢É„Åß„Éá„Éº„Çø„Éë„Ç§„Éó„ÇíÊßãÁØâ„Åô„Çã„Åü„ÇÅ„ÄÅPySpark„ÅÆ„Éè„É≥„Ç∫„Ç™„É≥ÁµåÈ®ì„Åå„ÅÇ„ÇãData Engineer„ÇíÂãüÈõÜ„ÄÇ\n\nPalantir Foundry Platform „ÅÆÁü•Ë≠ò„Åå„ÅÇ„Çå„Å∞Â∞öÂèØ„ÄÇhttps://t.co/MChra2E4kl https://t.co/7NYJQ07fbi", "public_metrics": {"retweet_count": 0, "reply_count": 0, "like_count": 22, "quote_count": 0, "impression_count": 2394}, "author_id": "1282707763282317315", "conversation_id": "1611211427372765185", "created_at": "2023-01-06T04:01:53.000Z"}, {"edit_history_tweet_ids": ["1611200621419581442"], "id": "1611200621419581442", "lang": "en", "text": "Just spent hours trying to wrangle my data with PySpark, but as usual, SQL comes in and saves the day. Being a data engineer is a rollercoaster ride of highs (SQL) and lows (everything else).", "public_metrics": {"retweet_count": 0, "reply_count": 0, "like_count": 0, "quote_count": 0, "impression_count": 3}, "author_id": "1603524644715130882", "conversation_id": "1611200621419581442", "created_at": "2023-01-06T03:18:57.000Z"}, {"edit_history_tweet_ids": ["1611199525762260992"], "id": "1611199525762260992", "lang": "en", "text": "RT @gp_pulipaka: Essential #PySpark for Scalable Data #Analytics! #BigData #DataScience #AI #MachineLearning #IoT #IIoT #Python #RStats #Te‚Ä¶", "public_metrics": {"retweet_count": 36, "reply_count": 0, "like_count": 0, "quote_count": 0, "impression_count": 0}, "author_id": "1142424032794406912", "conversation_id": "1611199525762260992", "created_at": "2023-01-06T03:14:36.000Z"}], "includes": {"users": [{"id": "46761170", "username": "marcoml", "created_at": "2009-06-12T22:09:48.000Z", "name": "Marco Mejia Lara"}, {"id": "1411245512980787203", "username": "TrajVoid", "created_at": "2021-07-03T08:49:05.000Z", "name": "Tushar Raj Verma"}, {"id": "1167839853184258049", "username": "PhilippeJB_PJB", "created_at": "2019-08-31T16:41:45.000Z", "name": "Philippe JEAN-BAPTISTE"}, {"id": "2311645130", "username": "AnalyticsVidhya", "created_at": "2014-01-26T10:48:31.000Z", "name": "Analytics Vidhya"}, {"id": "1078992647933448192", "username": "first_issues", "created_at": "2018-12-29T12:34:28.000Z", "name": "First Issues Bot"}, {"id": "527397291", "username": "OnekAlfred", "created_at": "2012-03-17T12:18:35.000Z", "name": "Onek Alfred"}, {"id": "766431397", "username": "gdorn1", "created_at": "2012-08-18T21:41:52.000Z", "name": "Gretchen Dorn"}, {"id": "1282707763282317315", "username": "racchikabu", "created_at": "2020-07-13T16:05:46.000Z", "name": "„Çâ„Å£„Å°@üá∫üá∏ÊäïË≥á3Âπ¥ÁîüüîÆ"}, {"id": "1603524644715130882", "username": "your_average_de", "created_at": "2022-12-15T22:57:53.000Z", "name": "Your Average Data Engineer"}, {"id": "1142424032794406912", "username": "CyberSecurityN8", "created_at": "2019-06-22T13:28:09.000Z", "name": "Cyber Security News"}]}, "meta": {"newest_id": "1611309217595392000", "oldest_id": "1611199525762260992", "result_count": 10, "next_token": "b26v89c19zqg8o3fqk3zrildgqivvmle99tw99nj96kjh"}}
{"data": [{"created_at": "2023-01-06T03:14:27.000Z", "lang": "en", "id": "1611199490978971648", "author_id": "104341297", "text": "RT @gp_pulipaka: Essential #PySpark for Scalable Data #Analytics! #BigData #DataScience #AI #MachineLearning #IoT #IIoT #Python #RStats #Te‚Ä¶", "edit_history_tweet_ids": ["1611199490978971648"], "conversation_id": "1611199490978971648", "public_metrics": {"retweet_count": 36, "reply_count": 0, "like_count": 0, "quote_count": 0, "impression_count": 0}}, {"created_at": "2023-01-06T02:37:00.000Z", "lang": "en", "id": "1611190064654028800", "author_id": "1562518867", "text": "üëã Say \"hello\" to transpiler, a Databricks Labs open-source project that automates the translation of Splunk SPL queries into scalable PySpark data frame operations.\n\nLearn moreüëá\nhttps://t.co/wUJnkqeUdn", "edit_history_tweet_ids": ["1611190064654028800"], "conversation_id": "1611190064654028800", "public_metrics": {"retweet_count": 2, "reply_count": 0, "like_count": 15, "quote_count": 0, "impression_count": 2841}}, {"created_at": "2023-01-06T01:57:53.000Z", "lang": "en", "id": "1611180219867750400", "author_id": "1529637984617697280", "text": "RT @gp_pulipaka: Essential #PySpark for Scalable Data #Analytics! #BigData #DataScience #AI #MachineLearning #IoT #IIoT #Python #RStats #Te‚Ä¶", "edit_history_tweet_ids": ["1611180219867750400"], "conversation_id": "1611180219867750400", "public_metrics": {"retweet_count": 36, "reply_count": 0, "like_count": 0, "quote_count": 0, "impression_count": 0}}, {"created_at": "2023-01-06T01:44:20.000Z", "lang": "en", "id": "1611176808942284801", "author_id": "992943418052460544", "text": "RT @gp_pulipaka: Essential #PySpark for Scalable Data #Analytics! #BigData #DataScience #AI #MachineLearning #IoT #IIoT #Python #RStats #Te‚Ä¶", "edit_history_tweet_ids": ["1611176808942284801"], "conversation_id": "1611176808942284801", "public_metrics": {"retweet_count": 36, "reply_count": 0, "like_count": 0, "quote_count": 0, "impression_count": 0}}], "includes": {"users": [{"username": "truciosnet", "created_at": "2010-01-13T01:46:48.000Z", "name": "JR Trucios", "id": "104341297"}, {"username": "databricks", "created_at": "2013-07-02T07:28:36.000Z", "name": "Databricks", "id": "1562518867"}, {"username": "CodingsBits", "created_at": "2022-05-26T01:38:23.000Z", "name": "Codings bits", "id": "1529637984617697280"}, {"username": "ricardo_ik_ahau", "created_at": "2018-05-06T01:45:33.000Z", "name": "Ricardo V√°zquez", "id": "992943418052460544"}]}, "meta": {"newest_id": "1611199490978971648", "oldest_id": "1611176808942284801", "result_count": 4}}
